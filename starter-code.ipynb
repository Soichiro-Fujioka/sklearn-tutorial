{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 気楽に始める scikit-learn 講座"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目次\n",
    "1. scilit-learnとは？\n",
    "1. 世界一簡単なモデル作成\n",
    "1. ちょっと深掘り\n",
    "1. モデル評価\n",
    "1. モデル保存と再利用\n",
    "1. 実際に分析してみる\n",
    "1. その他便利機能\n",
    "1. まとめ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# warningをオフにする (ほんとはだめ)\n",
    "warnings.simplefilter('ignore')\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. scikit-learnとは？\n",
    "* `scikit-learn` は現在最も普及している機械学習ライブラリです。  \n",
    "* 数行でモデルが作成できる手軽さから、機械学習エンジニア以外でも容易に使うことができるのが素敵です。\n",
    "* 前処理や性能評価など、モデル作成以外の機能も提供されているため、とりあえず困ったら `sklearn` を調べることが多いです。 (javascriptで言うところの、 `lodash` 的な…\n",
    "* 他の機械学習ライブラリも `sklearnライク` なインターフェースを提供していることも多く、デファクトスタンダード的な存在になっています。\n",
    "* **とりあえずこれを覚えておけ!** ライブラリです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 世界一簡単なモデル作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解説は後回しで `sklearn` の手軽さを体験します。  \n",
    "何はともあれデータのロードです (ちなみにガン診断のデータです"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データが揃ったので、モデルを作成してみます。  \n",
    "今回は患者のデータから、その患者がガンかどうかを判定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルの作成\n",
    "model = LogisticRegression()\n",
    "# 学習の開始\n",
    "model.fit(data.data, data.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これだけで学習モデルが完成しました。  \n",
    "モデルが出来たので、ちょっと予測してみます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted value:  [1]\n",
      "actual value:  0\n"
     ]
    }
   ],
   "source": [
    "print('predicted value: ', model.predict(data.data[3].reshape(1, -1)))\n",
    "print('actual value: ', data.target[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ちゃんと外れてますね…笑"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. ちょっと深掘り"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### インターフェースの利用\n",
    "`sklaern` にはたくさんの機械学習アルゴリズムが用意されていますが、使い方は統一されています。\n",
    "\n",
    "1. `hogemodel()` モデルで外枠を作成\n",
    "2. `fit()` で学習開始\n",
    "3. `predict()` で予測\n",
    "\n",
    "\n",
    "たった3ステップです。  そこで他のモデルも試してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [LogisticRegression(), SVC(), RandomForestClassifier()]\n",
    "trained_models = []\n",
    "\n",
    "# 3つ分のモデルを作成\n",
    "for model in models:\n",
    "    model.fit(data.data, data.target)\n",
    "    trained_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted value:  [0]\n",
      "actual value:  0\n"
     ]
    }
   ],
   "source": [
    "# RandomForestで検証\n",
    "print('predicted value: ', trained_models[2].predict(data.data[3].reshape(1, -1)))\n",
    "print('actual value: ', data.target[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `hogemodel` について\n",
    "* `sklearn` には多種多様なモデルが用意されていますが、各モデルの引数には、それぞれに合わせたモデルのオプションを指定します。  \n",
    "* これを外から設定するパラメータにちなんで **ハイパーパラメータ** と言います。  \n",
    "* ただし、sklearnには **デフォルトのハイパーパラメータでもうまくいくこと** が設計思想として盛り込まれています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted value:  [0]\n",
      "predicted value:  [1]\n"
     ]
    }
   ],
   "source": [
    "# ハイパーパラメータ C を変えてみる\n",
    "model1 = LogisticRegression(C=10, random_state=42)\n",
    "model2 = LogisticRegression(C=0.1, random_state=42)\n",
    "# なので推定結果が異なる\n",
    "model1.fit(data.data, data.target)\n",
    "model2.fit(data.data, data.target)\n",
    "print('predicted value: ', model1.predict(data.data[3].reshape(1, -1)))\n",
    "print('predicted value: ', model2.predict(data.data[3].reshape(1, -1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `fit`メソッドについて\n",
    "* モデルの学習は`fit`メソッドで行いますが、第一引数は学習データ, 第二引数は教師データです。\n",
    "* `fit` メソッド自体は単純ですが、これを行った後のmodelインスタンスは、学習済みモデルとなり、色々な情報が付加されています\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.66961014  0.08701507  0.3194159  -0.01172696 -0.02583376 -0.11308581\n",
      "  -0.16161837 -0.07059695 -0.03609787 -0.00644475  0.02286078  0.28965259\n",
      "   0.05778792 -0.07476975 -0.00254652 -0.02051683 -0.03054616 -0.00904964\n",
      "  -0.0083585  -0.00165526  0.66693723 -0.23022732 -0.21636029 -0.01551808\n",
      "  -0.04769816 -0.34625588 -0.43524746 -0.13641814 -0.1148247  -0.03257108]]\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(C=0.1, random_state=42)\n",
    "model.fit(data.data, data.target)\n",
    "# 推定されたパラメータを表示\n",
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `predict`メソッドについて\n",
    "* 学習済みのモデルに対して、予測を行う際には、`predict`メソッドを用います。\n",
    "* 使用したモデルによって、0or1を返すもの、10とか100返すもの様々です。\n",
    "* 0or1を返すものは、確率値を返す`predict_proba`メソッドも使えます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted value:  [1]\n",
      "predicted proba:  [[0.24566492 0.75433508]]\n"
     ]
    }
   ],
   "source": [
    "print('predicted value: ', model.predict(data.data[3].reshape(1, -1)))\n",
    "print('predicted proba: ', model.predict_proba(data.data[3].reshape(1, -1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.モデルの評価"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 学習モデルが本当によかったかどうかは、ちゃんと評価する必要があります。  \n",
    "* モデル評価用のメソッドももちろん用意されていますが、ここでは過学習について考えてみます。\n",
    "* 学習用と評価用のデータに分けて、未知のデータに対しても上手く予測できるモデルが良いモデルとなります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `train_test_split`メソッド\n",
    "* このメソッドは学習データとテストデータに分けるメソッドです。\n",
    "* ポイントはテストデータの中身を見ないことです。カンニングになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape X_train: (455, 30)\n",
      "shape X_test:  (114, 30)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.data, data.target, test_size=0.2, random_state=42)\n",
    "print('shape X_train:', X_train.shape)\n",
    "print('shape X_test: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 学習データとテストデータを作成したので、学習してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10000, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=42, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(C=10000, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `score`メソッド\n",
    "* scoreメソッドは、二値分類ではタスクでは、正答率(accuracy)と呼ばれる指標を計算します。\n",
    "* もちろん正答率以外の指標を計算するメソッドもたくさん用意されていて、状況に応じて使い分ける必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9802197802197802\n",
      "0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "print(model.score(X_train, y_train))\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* スコアみると学習データよりテストデータのスコアが低くなっています。\n",
    "* このように学習データに過剰に適合してしまっている状態を **過学習** と呼びます。\n",
    "* これでは未知のデータに対して上手く予測出来ないので、良いモデルとは言えません。\n",
    "* 目指すべきは正答率が高く、かつ学習データとテストデータの正答率が同じくらいのモデルです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. モデルの保存と再利用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 実際の運用ではリアルタイムの学習を行うことは、技術的、費用的コストが高いので、学習したモデルを保存しておき、再利用することが多いです。\n",
    "* 学習済みモデルをロード、`predict`メソッドの結果を返すのを関数化すると、それだけで立派な機械学習APIの出来あがりです。デバイスのEdgeに入れるのもありです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`joblib`ライブラリ\n",
    "* 学習済みモデルを外部ファイルに保存します。\n",
    "* ファイルは単なるバイナリなので、拡張子に指定はないですが、`pkl`が使われることが多いです。(漬物です\n",
    "* `dump`メソッドでモデルを保存します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soichiro.fujioka/ds-venv/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Logistic.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(model, 'Logistic.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 保存が完了したので、一旦モデルを削除し、ロードしてみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted value 0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "# モデルを削除\n",
    "del model\n",
    "# モデルを読み込み\n",
    "model = joblib.load('Logistic.pkl')\n",
    "print('predicted value', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 実際に分析してみる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ここまでの解説を踏まえて実際に分析してみたいと思います。\n",
    "* 実はここからがハンズオンです。\n",
    "* 今回はタイタニック号沈没事件の生存データを使ってみます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### データのロードと(簡単な前処理)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd #データフレームライブラリ\n",
    "titanic = pd.read_csv('./data/titanic.csv')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Survived` が生存したどうかのデータなので、その他のデータを使って予測してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 欠損値を確認\n",
    "titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データを教師データを分ける + 処理がめんどくさそうなデータを除く\n",
    "y_data = titanic[\"Survived\"]\n",
    "X_data = titanic.drop([\"PassengerId\", \"Survived\", \"Name\", \"Ticket\", \"Cabin\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文字列データはそのままでは扱えないので、数値データに変換\n",
    "X_data[\"Sex\"] = X_data[\"Sex\"].replace(\"male\", 1)\n",
    "X_data[\"Sex\"] = X_data[\"Sex\"].replace(\"female\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 欠損値をカテゴリとして扱う\n",
    "X_data[\"Embarked\"] = X_data[\"Embarked\"].fillna('Na')\n",
    "# ダミー変数化\n",
    "dummies = pd.get_dummies(X_data[\"Embarked\"])\n",
    "X_data['Q'] = dummies['Q']\n",
    "X_data['S'] = dummies['S']\n",
    "X_data['C'] = dummies['C']\n",
    "X_data.drop([\"Embarked\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Ageの欠損値を平均値で補完する\n",
    "X_data[\"Age\"] = X_data[\"Age\"].fillna(np.mean(X_data[\"Age\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ひとまずこれで最低限分析できるようになりました"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習データとテストデータに分ける"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_data, y_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* いくつかモデルを用意したので、モデルとパラメータを変えてみて、結果を違いを見てみましょう！\n",
    "* `command + /` で行のコメントアウトができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  0.8019662921348315\n",
      "test score:   0.8100558659217877\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(C=10, random_state=42) # C >= 0 で変更可能\n",
    "# model = SVC(C=1000, random_state=42) # C > 0 で変更可能\n",
    "# model = RandomForestClassifier(n_estimators=10 ,random_state=42) # n_estimators > 0 で変更可能\n",
    "# model = MLPClassifier(hidden_layer_sizes=(3, 10), random_state=42) # hidden_layer_sizesはタプルで共に1以上で変更可能\n",
    "model.fit(X_train, y_train) \n",
    "# 解析結果を表示\n",
    "print(\"train score: \", model.score(X_train, y_train))\n",
    "print(\"test score:  \", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. その他便利機能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ここまでモデルの構築をメインに`sklearn`の使い方を説明しましたが、その他にも処理を楽にする機能が用意されています。\n",
    "* ここではほんの一部を紹介します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### データの前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [ 1.,  1.],\n",
       "       [ 1.,  1.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[0, 0], [0, 0], [1, 1], [1, 1]]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data)\n",
    "scaler.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`StandardScaler`はデータの分散を1に平均を0にする操作です。数値計算の安定化の為によく使われます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 文字列データを数値に変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [['Male'], ['Female'], ['Female']]\n",
    "oneHotEncoder = OneHotEncoder()\n",
    "oneHotEncoder.fit(data)\n",
    "oneHotEncoder.transform(data).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### パイプライン\n",
    "* モデルにデータを食わせるまでのフローは固定されていることが多い為、パイプラインとして処理を構築するとスッキリとします。(一つのAPIの処理の流れが出来上がるイメージです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted value [0 0 0]\n"
     ]
    }
   ],
   "source": [
    "step = [\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', LogisticRegression())\n",
    "]\n",
    "pipeline = Pipeline(step)\n",
    "pipeline.fit(X_train, y_train)\n",
    "print('predicted value', pipeline.predict(X_train[0:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  0.8019662921348315\n",
      "test score:   0.8100558659217877\n"
     ]
    }
   ],
   "source": [
    "print(\"train score: \", pipeline.score(X_train, y_train))\n",
    "print(\"test score:  \", pipeline.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ここでは割愛しますが、先ほど手入力で行っていた、パラメータのチューニングや、より高度な精度評価(KFold CV)も行うことができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.まとめ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ここがGood\n",
    "* `sklearn`は簡単な記述でモデルを作成することができます。\n",
    "* 機械学習モデルの構築だけでなく、データの前処理やハイパーパラメータのチューニングを行うこともできます。\n",
    "* 基本的な機械学習タスクからニューラルネットまで構築できるので、とりあえず **POC**的作成しておくという使い方もできます\n",
    "* 一番使われているフレームワークなので、日本語資料もたくさんあります。\n",
    "\n",
    "#### ここがWeak\n",
    "* ディープニューラルネットやその他の高度な手法は別ライブラリに頼る必要がある(Tensorflow, Pytorchとか)\n",
    "* GPUが使えない"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
